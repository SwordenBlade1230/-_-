{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筆記\n",
    "* annotation version: tumor as kidney(DATA_0811_2)\n",
    "* INPUT_SIZE = 512\n",
    "* EPOCHS = 100\n",
    "* BATCH_SIZE = 2 (盡量符合過去的訓練環境以便比較不同的模型架構)\n",
    "* 有在Encoder中載入用ImageNet預訓練的模型參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取函式庫、超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 讀取函式庫 ###\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def solve_cudnn_error():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "solve_cudnn_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'DATA_0811_2\\\\WW600WL100'\n",
    "x_train_path = 'DATA_0811_2\\\\WW600WL100\\\\train\\\\images'\n",
    "y_train_path = 'DATA_0811_2\\\\WW600WL100\\\\train\\\\annotations_tumor as kidney'\n",
    "checkpoints_path = 'DATA_0811_2\\WW600WL100\\\\Model_ResNet50V2-Unet_0906'\n",
    "model_name = 'ResNet50V2-Unet'\n",
    "start_from_latest_checkpoints = False\n",
    "\n",
    "INPUT_SIZE = 512 # input size equal to output size\n",
    "CLASS_NUM = 2 # background and roi(kidney)\n",
    "\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "IMAGE_ORDERING = 'channels_last' # 不要亂改這個參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用生成器(generator)生成訓練圖片\n",
    "使用generator的好處在於，模型在訓練(或驗證)的過程中會依據批量大小生成圖片，不需要在程式中預先準備好資料集(通常資料集都會大到無法一口氣塞入記憶體之中)，減少記憶體的使用空間。另外，使用ImageDataGenerator可以對生成的圖片實施「資料增強(Data Augmentation)」，增加模型的泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### 取得資料集中所有的檔案路徑(包含CT影像和其對應標記的路徑) ###\n",
    "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False):\n",
    "    \"\"\" Find all the images from the images_path directory and\n",
    "        the segmentation images from the segs_path directory\n",
    "        while checking integrity of data \"\"\"\n",
    "\n",
    "    ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "    ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n",
    "\n",
    "    image_files = []\n",
    "    segmentation_files = {}\n",
    "\n",
    "    for dir_entry in os.listdir(images_path):\n",
    "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
    "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            image_files.append((file_name, file_extension,\n",
    "                                os.path.join(images_path, dir_entry)))\n",
    "\n",
    "    for dir_entry in os.listdir(segs_path):\n",
    "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
    "           os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            full_dir_entry = os.path.join(segs_path, dir_entry)\n",
    "            if file_name in segmentation_files:\n",
    "                raise DataLoaderError(\"Segmentation file with filename {0}\"\n",
    "                                      \" already exists and is ambiguous to\"\n",
    "                                      \" resolve with path {1}.\"\n",
    "                                      \" Please remove or rename the latter.\"\n",
    "                                      .format(file_name, full_dir_entry))\n",
    "\n",
    "            segmentation_files[file_name] = (file_extension, full_dir_entry)\n",
    "\n",
    "    return_value = []\n",
    "    # Match the images and segmentations\n",
    "    for image_file, _, image_full_path in image_files:\n",
    "        if image_file in segmentation_files:\n",
    "            return_value.append((image_full_path,\n",
    "                                segmentation_files[image_file][1]))\n",
    "        elif ignore_non_matching:\n",
    "            continue\n",
    "        else:\n",
    "            # Error out\n",
    "            raise DataLoaderError(\"No corresponding segmentation \"\n",
    "                                  \"found for image {0}.\"\n",
    "                                  .format(image_full_path))\n",
    "\n",
    "    return return_value\n",
    "\n",
    "### 將CT影像的陣列轉成適合模型輸入的形式(維度轉換 + 標準化) ###\n",
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first'):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, 1)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\": # 除以127.5，然後減 1\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\": # 減去ImageNet的平均BGR\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img[:, :, 0] -= 103.939\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 123.68\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\": # 除以255\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img\n",
    "\n",
    "### 將標記資料的陣列轉成適合模型輸入的形式(維度轉換) ###\n",
    "def get_segmentation_array(image_input, nClasses,\n",
    "                           width, height, no_reshape=False):\n",
    "    \"\"\" Load segmentation array from input \"\"\"\n",
    "\n",
    "    seg_labels = np.zeros((height, width, nClasses))\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                                  \"path {0} doesn't exist\".format(image_input))\n",
    "        img = cv2.imread(image_input, 1)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                              \"Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    img = img[:, :, 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[:, :, c] = (img == c).astype(int)\n",
    "\n",
    "    if not no_reshape:\n",
    "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
    "\n",
    "    return seg_labels\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
    "                                 n_classes, input_height, input_width,\n",
    "                                 output_height, output_width, do_augment=False):\n",
    "\n",
    "    img_seg_pairs = get_pairs_from_paths(images_path, segs_path) \n",
    "        # 取得資料集中所有的檔案路徑(包含CT影像和其對應標記的路徑)\n",
    "    random.shuffle(img_seg_pairs) # 打散檔案路徑\n",
    "    zipped = itertools.cycle(img_seg_pairs) \n",
    "        # 將檔案路徑用循環迭代器(iterator)封裝；範例：cycle('ABCD') --> A B C D A B C D ...\n",
    "#     counter = 0\n",
    "\n",
    "    while True:\n",
    "        # 如果模型訓練完一輪訓練集中所有的資料，就重新打散檔案路徑\n",
    "#         if counter >= len(img_seg_pairs):\n",
    "#             counter = 0\n",
    "#             random.shuffle(img_seg_pairs)\n",
    "#             zipped = itertools.cycle(img_seg_pairs)             \n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range(batch_size): # batch_size多大，就取得多少份資料\n",
    "#             counter += 1\n",
    "            \n",
    "            im, seg = next(zipped) # 取得CT影像和其對應標記的路徑\n",
    "\n",
    "            im = cv2.imread(im, 1) # 1 = cv2.IMREAD_COLOR (讀取彩色圖片)\n",
    "            seg = cv2.imread(seg, 1)\n",
    "            \n",
    "            if do_augment:\n",
    "                ### Example of transforming images and masks together. ###\n",
    "                # we create two instances with the same arguments\n",
    "                data_gen_args = dict(featurewise_center=False, # 範例程式碼為True，但這裡我只是要把一張圖片變成是增強後的型態\n",
    "                         featurewise_std_normalization=False, # 範例程式碼為True，但這裡我只是要把一張圖片變成是增強後的型態\n",
    "                         #rotation_range=30, # 範例程式碼為90\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "                image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "                mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "                # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "                seed = random.randint(0,10000)\n",
    "                im_itr = image_datagen.flow(im.reshape(1, 512, 512, 3), batch_size=1, seed=seed)  \n",
    "                seg_itr = mask_datagen.flow(seg.reshape(1, 512, 512, 3), batch_size=1, seed=seed)  \n",
    "                im = next(im_itr).reshape(512, 512, 3)\n",
    "                seg = next(seg_itr).reshape(512, 512, 3)\n",
    "            \n",
    "            # 將CT影像和其對應的標記轉換成模型輸入的形式\n",
    "            X.append(get_image_array(im, input_width,\n",
    "                                     input_height, imgNorm=\"sub_mean\", ordering=IMAGE_ORDERING)) \n",
    "                # imgNorm預設為sub_mean\"，但這裡我改用圖片最常實施的正規化方法(同除以255)\n",
    "            Y.append(get_segmentation_array(\n",
    "                seg, n_classes, output_width, output_height))\n",
    "\n",
    "        yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立訓練資料的生成器\n",
    "train_gen = image_segmentation_generator(images_path = x_train_path, segs_path = y_train_path, batch_size = BATCH_SIZE, \n",
    "                                         n_classes = CLASS_NUM, input_height = INPUT_SIZE, input_width = INPUT_SIZE, \n",
    "                                         output_height = INPUT_SIZE, output_width = INPUT_SIZE, do_augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定回調函式(callbacks)\n",
    "keras_segmentation自定義的回調函式好像缺了什麼，直接用在這份程式碼中並不會正常運作，因此我直接用keras.callbacks.ModelCheckpoint定期儲存模型參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "callbacks = [ModelCheckpoint(os.path.join(checkpoints_path, model_name + '_{epoch}.h5'), \n",
    "                             save_weights_only=True, \n",
    "                             period=5)] # period=5：每5個Epoch才會儲存一次參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eecoder - ResNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, strides=1):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    name_base = 'conv' + str(stage) + '_' + 'block' + block\n",
    "    \n",
    "    preact = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                       name=name_base + '_preact_bn')(input_tensor)\n",
    "    preact = Activation('relu', name=name_base + '_preact_relu')(preact)\n",
    "    \n",
    "    shortcut = MaxPooling2D(1, strides=strides)(input_tensor) if strides > 1 else input_tensor\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=1, use_bias=False,\n",
    "               name=name_base + '_1_conv')(preact)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name_base + '_2_pad')(x)\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING, strides=strides,\n",
    "               use_bias=False, name=name_base + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=name_base + '_3_conv')(x)\n",
    "\n",
    "    x = Add(name=name_base + '_out')([shortcut, x])\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=1):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    name_base = 'conv' + str(stage) + '_' + 'block' + block  \n",
    "        \n",
    "    preact = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                       name=name_base + '_preact_bn')(input_tensor)\n",
    "    preact = Activation('relu', name=name_base + '_preact_relu')(preact)\n",
    "    \n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING, \n",
    "                      strides=strides, name=name_base + '_0_conv')(preact)\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=1, use_bias=False,\n",
    "               name=name_base + '_1_conv')(preact)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name_base + '_2_pad')(x)\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING, strides=strides,\n",
    "               use_bias=False, name=name_base + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=name_base + '_3_conv')(x)\n",
    "\n",
    "    x = Add(name=name_base + '_out')([shortcut, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = input_width = INPUT_SIZE\n",
    "n_classes = classes = CLASS_NUM\n",
    "use_bias = True # True for ResNet and ResNetV2, False for ResNeXt\n",
    "bn_axis = 3 if IMAGE_ORDERING == 'channels_last' else 1\n",
    "\n",
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "### conv1 ###\n",
    "x = ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "x = Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "f0 = x\n",
    "x = ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "x = MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "f1 = x\n",
    "\n",
    "### conv2 ###\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='1', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='2')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='3', strides=2)\n",
    "f2 = x\n",
    "#f2 = one_side_pad(x)\n",
    "\n",
    "### conv3 ###\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='1')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='2')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='3')\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='4', strides=2)\n",
    "f3 = x\n",
    "\n",
    "### conv4 ###\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='1')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='2')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='3')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='4')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='5')\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='6', strides=2)\n",
    "f4 = x\n",
    "\n",
    "### conv5 ###\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='1')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='2')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='3', strides=1)\n",
    "f5 = x\n",
    "\n",
    "x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name='post_bn')(x)\n",
    "x = Activation('relu', name='post_relu')(x)\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dense(1000, activation='softmax', name='probs')(x) \n",
    "    # 為了能對Eecoder載入keras.applications用imagenet預訓練的參數，因此輸出層的神經元設成1000而非標記的類別數量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 對Eecoder載入keras.applications用imagenet預訓練的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WEIGHTS_PATH = (\n",
    "    'https://github.com/keras-team/keras-applications/'\n",
    "    'releases/download/resnet/')\n",
    "WEIGHTS_HASHES = {\n",
    "    'resnet50': ('2cb95161c43110f7111970584f804107',\n",
    "                 '4d473c1dd8becc155b73f8504c6f6626'),\n",
    "    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',\n",
    "                  '88cf7a10940856eca736dc7b7e228a21'),\n",
    "    'resnet152': ('100835be76be38e30d865e96f2aaae62',\n",
    "                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),\n",
    "    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',\n",
    "                   'fac2f116257151a9d068a22e544a4917'),\n",
    "    'resnet101v2': ('6343647c601c52e1368623803854d971',\n",
    "                    'c0ed64b8031c3730f411d2eb4eea35b5'),\n",
    "    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',\n",
    "                    'ed17cf2e0169df9d443503ef94b23b33'),\n",
    "    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',\n",
    "                  '62527c363bdd9ec598bed41947b379fc'),\n",
    "    'resnext101': ('34fb605428fcc7aa4d62f44404c11509',\n",
    "                   '0f678c91647380debd923963594981b3')\n",
    "}\n",
    "\n",
    "model_name='resnet50v2'\n",
    "file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "file_hash = WEIGHTS_HASHES[model_name][0]\n",
    "\n",
    "weights_path = keras.utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)\n",
    "Model(img_input, x).load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder (這裡我有為了讓輸出大小和輸入大小保持一致新增一個含有上取樣層的block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "o = f4\n",
    "\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f3], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f2], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f1], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f0], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = Conv2D(n_classes, (3, 3), padding='same', data_format=IMAGE_ORDERING)(o) # 輸出層\n",
    "\n",
    "## 模仿 keras_segmentation 在輸出層之後額外添加這幾層 ###\n",
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    o = (Reshape((n_classes, INPUT_SIZE * INPUT_SIZE)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    o = (Reshape((INPUT_SIZE * INPUT_SIZE, n_classes)))(o)\n",
    "o = (Activation('softmax'))(o)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(img_input, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看模型架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 128, 128, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 128, 128, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 128, 128, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 128, 128, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 128, 128, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 64, 64, 256)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 64, 64, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 64, 64, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 32, 32, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 512)  0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 32, 32, 512)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 32, 32, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 16, 16, 1024) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 18, 18, 1024) 0           conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 512)  4719104     zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 512)  2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 1024) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 256)  2359552     zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  589952      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 130, 130, 192 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 221312      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 258, 258, 192 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 64) 110656      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 514, 514, 64) 0           up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 64) 36928       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 512, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 512, 2)  1154        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 262144, 2)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 262144, 2)    0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 16,616,706\n",
      "Trainable params: 16,589,442\n",
      "Non-trainable params: 27,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入模型參數(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('DATA_0811_2\\WW600WL100\\\\Model_ResNet50V2-Unet_0906\\\\ResNet50V2-Unet_100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Adadelta\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adadelta(lr = 1.0),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "print(K.eval(model.optimizer.lr)) # 確保是1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 即將用該資料集進行訓練：DATA_0811_2\\WW600WL100 ##########\n",
      "-----建立新資料夾：DATA_0811_2\\WW600WL100\\Model_ResNet50V2-Unet_0906-----\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 150s 294ms/step - loss: 0.1286 - accuracy: 0.9640\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 124s 242ms/step - loss: 0.0459 - accuracy: 0.9900\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 124s 242ms/step - loss: 0.0472 - accuracy: 0.9894\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0486 - accuracy: 0.9885\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 123s 241ms/step - loss: 0.0451 - accuracy: 0.9896\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 124s 242ms/step - loss: 0.0323 - accuracy: 0.9917\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0194 - accuracy: 0.9940\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0114 - accuracy: 0.9964\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0089 - accuracy: 0.9971\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0075 - accuracy: 0.9975\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0058 - accuracy: 0.9981\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0053 - accuracy: 0.9983\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0051 - accuracy: 0.9982\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0055 - accuracy: 0.9981\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0037 - accuracy: 0.9987\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0033 - accuracy: 0.9988\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0027 - accuracy: 0.9990\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0050 - accuracy: 0.9984\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 122s 239ms/step - loss: 0.0023 - accuracy: 0.9991\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0022 - accuracy: 0.9992\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 124s 242ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0040 - accuracy: 0.9987\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0018 - accuracy: 0.9993\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0020 - accuracy: 0.9993\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0023 - accuracy: 0.9992\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0017 - accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 122s 239ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.9158e-04 - accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.3031e-04 - accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 77/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.7977e-04 - accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 123s 241ms/step - loss: 9.5321e-04 - accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 124s 242ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.4896e-04 - accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.4294e-04 - accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.5396e-04 - accuracy: 0.9996\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.2454e-04 - accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 123s 239ms/step - loss: 9.8307e-04 - accuracy: 0.9996\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.0461e-04 - accuracy: 0.9996\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.9642e-04 - accuracy: 0.9996\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 123s 241ms/step - loss: 9.0366e-04 - accuracy: 0.9996\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.4975e-04 - accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.6733e-04 - accuracy: 0.9996\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 8.0735e-04 - accuracy: 0.9997\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 8.3382e-04 - accuracy: 0.9997\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 123s 240ms/step - loss: 9.1516e-04 - accuracy: 0.9996\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 123s 241ms/step - loss: 8.9095e-04 - accuracy: 0.9996\n",
      "花費時間(秒)：12471.446732282639\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "print(f'########## 即將用該資料集進行訓練：{dataset_dir} ##########')\n",
    "\n",
    "if start_from_latest_checkpoints:\n",
    "    try:\n",
    "        model.load_weights(\n",
    "            os.path.join(\n",
    "                checkpoints_path, \n",
    "                model_name + '_' + str(max([int(i.split('_')[-1][:-3]) for i in os.listdir(checkpoints_path)])) + '.h5'\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        print('Model weights not found!')\n",
    "\n",
    "if not os.path.exists(checkpoints_path):\n",
    "    os.makedirs(checkpoints_path)\n",
    "    print('-----建立新資料夾：' + checkpoints_path + '-----') \n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch = 512, \n",
    "    #steps_per_epoch = len(x_train) // BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "ed = time.time()\n",
    "spend_time = ed - st\n",
    "print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型預測結果(測試集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12656/12656 [09:05<00:00, 23.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import *\n",
    "preds = predict_from_folder(model, 'DATA_0811_2\\\\WW600WL100\\\\test\\\\images', INPUT_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------開始計算各項預測指標----------\n",
      "目前進度：第500張照片\n",
      "目前進度：第1000張照片\n",
      "目前進度：第1500張照片\n",
      "目前進度：第2000張照片\n",
      "目前進度：第2500張照片\n",
      "目前進度：第3000張照片\n",
      "目前進度：第3500張照片\n",
      "目前進度：第4000張照片\n",
      "目前進度：第4500張照片\n",
      "目前進度：第5000張照片\n",
      "目前進度：第5500張照片\n",
      "目前進度：第6000張照片\n",
      "目前進度：第6500張照片\n",
      "目前進度：第7000張照片\n",
      "目前進度：第7500張照片\n",
      "目前進度：第8000張照片\n",
      "目前進度：第8500張照片\n",
      "目前進度：第9000張照片\n",
      "目前進度：第9500張照片\n",
      "目前進度：第10000張照片\n",
      "目前進度：第10500張照片\n",
      "目前進度：第11000張照片\n",
      "目前進度：第11500張照片\n",
      "目前進度：第12000張照片\n",
      "目前進度：第12500張照片\n",
      "total case number: 12656\n",
      "訓練集預測結果：\n",
      "average Dice score per case of kidney:  0.9546\n",
      "average recall of kidney:  0.9315\n",
      "average precision of kidney:  0.9809\n",
      "global dice score of kidney:  0.9469\n",
      "\n",
      "混淆矩陣：\n",
      "True Positive: 4021\n",
      "False Positive: 77\n",
      "False Negative: 98\n",
      "True Negative: 8460\n",
      "花費時間(秒)：685.9001486301422\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "result = evaluate_model(\n",
    "    image_dir = os.path.join(dataset_dir, 'test', 'images'), \n",
    "    label_dir = os.path.join(dataset_dir, 'test', 'annotations_tumor as kidney'), \n",
    "    checkpoints_path = None,\n",
    "    calculate_predicting_indicators = True,\n",
    "    output_predicted_result = False, \n",
    "    segment_out_predicted_region_from_original_images = False, \n",
    "    roi_description = 'tumor as kidney', \n",
    "    preds = preds)\n",
    "\n",
    "print('訓練集預測結果：')\n",
    "print(f'average Dice score per case of kidney: {result[0]: .4f}')\n",
    "print(f'average recall of kidney: {result[1]: .4f}')\n",
    "print(f'average precision of kidney: {result[2]: .4f}')\n",
    "print(f'global dice score of kidney: {result[3]: .4f}')\n",
    "print('')\n",
    "print('混淆矩陣：')\n",
    "print(f'True Positive: {result[-4]}')\n",
    "print(f'False Positive: {result[-3]}')\n",
    "print(f'False Negative: {result[-2]}')\n",
    "print(f'True Negative: {result[-1]}')\n",
    "\n",
    "ed = time.time()\n",
    "spend_time = ed - st\n",
    "print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試集各病患的 Dice score:\n",
      "case150:  0.9772\n",
      "case151:  0.7931\n",
      "case152:  0.9769\n",
      "case153:  0.9707\n",
      "case154:  0.9547\n",
      "case155:  0.9557\n",
      "case156:  0.9679\n",
      "case157:  0.9585\n",
      "case158:  0.9712\n",
      "case159:  0.9687\n",
      "case160:  0.9608\n",
      "case161:  0.9486\n",
      "case162:  0.9590\n",
      "case163:  0.9717\n",
      "case164:  0.9621\n",
      "case165:  0.9770\n",
      "case166:  0.9586\n",
      "case167:  0.9824\n",
      "case168:  0.9583\n",
      "case169:  0.9752\n",
      "case170:  0.9487\n",
      "case171:  0.9772\n",
      "case172:  0.9374\n",
      "case173:  0.9683\n",
      "case174:  0.9730\n",
      "case175:  0.9636\n",
      "case176:  0.9428\n",
      "case177:  0.9455\n",
      "case178:  0.8845\n",
      "case179:  0.9686\n",
      "case181:  0.9513\n",
      "case182:  0.9633\n",
      "case183:  0.9665\n",
      "case184:  0.9217\n",
      "case185:  0.9772\n",
      "case186:  0.9748\n",
      "case187:  0.9127\n",
      "case188:  0.9487\n",
      "case189:  0.8583\n",
      "case190:  0.9462\n",
      "case191:  0.9731\n",
      "case192:  0.9465\n",
      "case193:  0.9757\n",
      "case194:  0.9478\n",
      "case195:  0.9692\n",
      "case196:  0.9797\n",
      "case197:  0.8979\n",
      "case198:  0.9602\n",
      "case199:  0.9525\n",
      "case200:  0.9527\n",
      "case201:  0.9803\n",
      "case202:  0.9651\n",
      "case204:  0.9749\n",
      "case205:  0.9728\n",
      "case206:  0.9411\n",
      "case207:  0.9766\n",
      "case208:  0.9451\n",
      "case209:  0.9762\n"
     ]
    }
   ],
   "source": [
    "f = open(\"DATA_0811_2\\\\patient indices of testing set - KiTS.txt\", \"r\")\n",
    "test_patient_idx = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "dice_score_list = result[5]\n",
    "print('測試集各病患的 Dice score:')\n",
    "for idx, i in enumerate(dice_score_list):\n",
    "    print(f'case{test_patient_idx[idx]}: {i: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = time.time()\n",
    "\n",
    "# from evaluate import *\n",
    "# _ = evaluate_model(\n",
    "#     image_dir = os.path.join(dataset_dir, 'test', 'images'), \n",
    "#     label_dir = os.path.join(dataset_dir, 'test', 'annotations_tumor as kidney'), \n",
    "#     checkpoints_path = None,\n",
    "#     calculate_predicting_indicators = False,\n",
    "#     output_predicted_result = True, \n",
    "#     segment_out_predicted_region_from_original_images = True, \n",
    "#     roi_description = 'tumor as kidney', \n",
    "#     preds = preds\n",
    "# )\n",
    "\n",
    "# ed = time.time()\n",
    "# spend_time = ed - st\n",
    "# print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_result(\n",
    "#     target_dataset_base_dir = 'DATA_0811_2\\\\WW600WL100\\\\test',\n",
    "#     result_num = 10,\n",
    "#     roi_description = 'tumor as kidney', \n",
    "#     roi_name_chinese = '腎臟',\n",
    "#     show_predicted_result = True,\n",
    "#     show_segmentation_result = True, \n",
    "#     image_scale = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
