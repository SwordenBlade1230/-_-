{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 筆記\n",
    "* annotation version: tumor as kidney(DATA_0811_2)\n",
    "* INPUT_SIZE = 512\n",
    "* EPOCHS = 100\n",
    "* BATCH_SIZE = 2 (BATCH_SIZE = 4 電腦跑不動)\n",
    "* 有在Encoder中載入用ImageNet預訓練的模型參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 讀取函式庫、超參數設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 讀取函式庫 ###\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "def solve_cudnn_error():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            # Currently, memory growth needs to be the same across GPUs\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "            print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "        except RuntimeError as e:\n",
    "            # Memory growth must be set before GPUs have been initialized\n",
    "            print(e)\n",
    "\n",
    "solve_cudnn_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'DATA_0811_2\\\\WW600WL100'\n",
    "x_train_path = 'DATA_0811_2\\\\WW600WL100\\\\train\\\\images'\n",
    "y_train_path = 'DATA_0811_2\\\\WW600WL100\\\\train\\\\annotations_tumor as kidney'\n",
    "checkpoints_path = 'DATA_0811_2\\WW600WL100\\\\Model_0905_V2'\n",
    "model_name = 'ResNet152V2-Unet'\n",
    "start_from_latest_checkpoints = False\n",
    "\n",
    "INPUT_SIZE = 512 # input size equal to output size\n",
    "CLASS_NUM = 2 # background and roi(kidney)\n",
    "\n",
    "# initialize the number of epochs and batch size\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2\n",
    "\n",
    "IMAGE_ORDERING = 'channels_last' # 不要亂改這個參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 用生成器(generator)生成訓練圖片\n",
    "使用generator的好處在於，模型在訓練(或驗證)的過程中會依據批量大小生成圖片，不需要在程式中預先準備好資料集(通常資料集都會大到無法一口氣塞入記憶體之中)，減少記憶體的使用空間。另外，使用ImageDataGenerator可以對生成的圖片實施「資料增強(Data Augmentation)」，增加模型的泛化能力。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### 取得資料集中所有的檔案路徑(包含CT影像和其對應標記的路徑) ###\n",
    "def get_pairs_from_paths(images_path, segs_path, ignore_non_matching=False):\n",
    "    \"\"\" Find all the images from the images_path directory and\n",
    "        the segmentation images from the segs_path directory\n",
    "        while checking integrity of data \"\"\"\n",
    "\n",
    "    ACCEPTABLE_IMAGE_FORMATS = [\".jpg\", \".jpeg\", \".png\", \".bmp\"]\n",
    "    ACCEPTABLE_SEGMENTATION_FORMATS = [\".png\", \".bmp\"]\n",
    "\n",
    "    image_files = []\n",
    "    segmentation_files = {}\n",
    "\n",
    "    for dir_entry in os.listdir(images_path):\n",
    "        if os.path.isfile(os.path.join(images_path, dir_entry)) and \\\n",
    "                os.path.splitext(dir_entry)[1] in ACCEPTABLE_IMAGE_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            image_files.append((file_name, file_extension,\n",
    "                                os.path.join(images_path, dir_entry)))\n",
    "\n",
    "    for dir_entry in os.listdir(segs_path):\n",
    "        if os.path.isfile(os.path.join(segs_path, dir_entry)) and \\\n",
    "           os.path.splitext(dir_entry)[1] in ACCEPTABLE_SEGMENTATION_FORMATS:\n",
    "            file_name, file_extension = os.path.splitext(dir_entry)\n",
    "            full_dir_entry = os.path.join(segs_path, dir_entry)\n",
    "            if file_name in segmentation_files:\n",
    "                raise DataLoaderError(\"Segmentation file with filename {0}\"\n",
    "                                      \" already exists and is ambiguous to\"\n",
    "                                      \" resolve with path {1}.\"\n",
    "                                      \" Please remove or rename the latter.\"\n",
    "                                      .format(file_name, full_dir_entry))\n",
    "\n",
    "            segmentation_files[file_name] = (file_extension, full_dir_entry)\n",
    "\n",
    "    return_value = []\n",
    "    # Match the images and segmentations\n",
    "    for image_file, _, image_full_path in image_files:\n",
    "        if image_file in segmentation_files:\n",
    "            return_value.append((image_full_path,\n",
    "                                segmentation_files[image_file][1]))\n",
    "        elif ignore_non_matching:\n",
    "            continue\n",
    "        else:\n",
    "            # Error out\n",
    "            raise DataLoaderError(\"No corresponding segmentation \"\n",
    "                                  \"found for image {0}.\"\n",
    "                                  .format(image_full_path))\n",
    "\n",
    "    return return_value\n",
    "\n",
    "### 將CT影像的陣列轉成適合模型輸入的形式(維度轉換 + 標準化) ###\n",
    "def get_image_array(image_input,\n",
    "                    width, height,\n",
    "                    imgNorm=\"sub_mean\", ordering='channels_first'):\n",
    "    \"\"\" Load image array from input \"\"\"\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_image_array: path {0} doesn't exist\"\n",
    "                                  .format(image_input))\n",
    "        img = cv2.imread(image_input, 1)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_image_array: Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    if imgNorm == \"sub_and_divide\": # 除以127.5，然後減 1\n",
    "        img = np.float32(cv2.resize(img, (width, height))) / 127.5 - 1\n",
    "    elif imgNorm == \"sub_mean\": # 減去ImageNet的平均BGR\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img[:, :, 0] -= 103.939\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 123.68\n",
    "        img = img[:, :, ::-1]\n",
    "    elif imgNorm == \"divide\": # 除以255\n",
    "        img = cv2.resize(img, (width, height))\n",
    "        img = img.astype(np.float32)\n",
    "        img = img/255.0\n",
    "\n",
    "    if ordering == 'channels_first':\n",
    "        img = np.rollaxis(img, 2, 0)\n",
    "    return img\n",
    "\n",
    "### 將標記資料的陣列轉成適合模型輸入的形式(維度轉換) ###\n",
    "def get_segmentation_array(image_input, nClasses,\n",
    "                           width, height, no_reshape=False):\n",
    "    \"\"\" Load segmentation array from input \"\"\"\n",
    "\n",
    "    seg_labels = np.zeros((height, width, nClasses))\n",
    "\n",
    "    if type(image_input) is np.ndarray:\n",
    "        # It is already an array, use it as it is\n",
    "        img = image_input\n",
    "    elif isinstance(image_input, six.string_types):\n",
    "        if not os.path.isfile(image_input):\n",
    "            raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                                  \"path {0} doesn't exist\".format(image_input))\n",
    "        img = cv2.imread(image_input, 1)\n",
    "    else:\n",
    "        raise DataLoaderError(\"get_segmentation_array: \"\n",
    "                              \"Can't process input type {0}\"\n",
    "                              .format(str(type(image_input))))\n",
    "\n",
    "    img = cv2.resize(img, (width, height), interpolation=cv2.INTER_NEAREST)\n",
    "    img = img[:, :, 0]\n",
    "\n",
    "    for c in range(nClasses):\n",
    "        seg_labels[:, :, c] = (img == c).astype(int)\n",
    "\n",
    "    if not no_reshape:\n",
    "        seg_labels = np.reshape(seg_labels, (width*height, nClasses))\n",
    "\n",
    "    return seg_labels\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def image_segmentation_generator(images_path, segs_path, batch_size,\n",
    "                                 n_classes, input_height, input_width,\n",
    "                                 output_height, output_width, do_augment=False):\n",
    "\n",
    "    img_seg_pairs = get_pairs_from_paths(images_path, segs_path) \n",
    "        # 取得資料集中所有的檔案路徑(包含CT影像和其對應標記的路徑)\n",
    "    random.shuffle(img_seg_pairs) # 打散檔案路徑\n",
    "    zipped = itertools.cycle(img_seg_pairs) \n",
    "        # 將檔案路徑用循環迭代器(iterator)封裝；範例：cycle('ABCD') --> A B C D A B C D ...\n",
    "#     counter = 0\n",
    "\n",
    "    while True:\n",
    "        # 如果模型訓練完一輪訓練集中所有的資料，就重新打散檔案路徑\n",
    "#         if counter >= len(img_seg_pairs):\n",
    "#             counter = 0\n",
    "#             random.shuffle(img_seg_pairs)\n",
    "#             zipped = itertools.cycle(img_seg_pairs)             \n",
    "        \n",
    "        X = []\n",
    "        Y = []\n",
    "        for _ in range(batch_size): # batch_size多大，就取得多少份資料\n",
    "#             counter += 1\n",
    "            \n",
    "            im, seg = next(zipped) # 取得CT影像和其對應標記的路徑\n",
    "\n",
    "            im = cv2.imread(im, 1) # 1 = cv2.IMREAD_COLOR (讀取彩色圖片)\n",
    "            seg = cv2.imread(seg, 1)\n",
    "            \n",
    "            if do_augment:\n",
    "                ### Example of transforming images and masks together. ###\n",
    "                # we create two instances with the same arguments\n",
    "                data_gen_args = dict(featurewise_center=False, # 範例程式碼為True，但這裡我只是要把一張圖片變成是增強後的型態\n",
    "                         featurewise_std_normalization=False, # 範例程式碼為True，但這裡我只是要把一張圖片變成是增強後的型態\n",
    "                         #rotation_range=30, # 範例程式碼為90\n",
    "                         width_shift_range=0.1,\n",
    "                         height_shift_range=0.1,\n",
    "                         zoom_range=0.2)\n",
    "                image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "                mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "                # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "                seed = random.randint(0,10000)\n",
    "                im_itr = image_datagen.flow(im.reshape(1, 512, 512, 3), batch_size=1, seed=seed)  \n",
    "                seg_itr = mask_datagen.flow(seg.reshape(1, 512, 512, 3), batch_size=1, seed=seed)  \n",
    "                im = next(im_itr).reshape(512, 512, 3)\n",
    "                seg = next(seg_itr).reshape(512, 512, 3)\n",
    "            \n",
    "            # 將CT影像和其對應的標記轉換成模型輸入的形式\n",
    "            X.append(get_image_array(im, input_width,\n",
    "                                     input_height, imgNorm=\"sub_mean\", ordering=IMAGE_ORDERING)) \n",
    "                # imgNorm預設為sub_mean\"，但這裡我改用圖片最常實施的正規化方法(同除以255)\n",
    "            Y.append(get_segmentation_array(\n",
    "                seg, n_classes, output_width, output_height))\n",
    "\n",
    "        yield np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立訓練資料的生成器\n",
    "train_gen = image_segmentation_generator(images_path = x_train_path, segs_path = y_train_path, batch_size = BATCH_SIZE, \n",
    "                                         n_classes = CLASS_NUM, input_height = INPUT_SIZE, input_width = INPUT_SIZE, \n",
    "                                         output_height = INPUT_SIZE, output_width = INPUT_SIZE, do_augment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定回調函式(callbacks)\n",
    "keras_segmentation自定義的回調函式好像缺了什麼，直接用在這份程式碼中並不會正常運作，因此我直接用keras.callbacks.ModelCheckpoint定期儲存模型參數。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "callbacks = [ModelCheckpoint(os.path.join(checkpoints_path, model_name + '_{epoch}.h5'), \n",
    "                             save_weights_only=True, \n",
    "                             period=5)] # period=5：每5個Epoch才會儲存一次參數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Eecoder - ResNet152V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(input_tensor, kernel_size, filters, stage, block, strides=1):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "\n",
    "    name_base = 'conv' + str(stage) + '_' + 'block' + block\n",
    "    \n",
    "    preact = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                       name=name_base + '_preact_bn')(input_tensor)\n",
    "    preact = Activation('relu', name=name_base + '_preact_relu')(preact)\n",
    "    \n",
    "    shortcut = MaxPooling2D(1, strides=strides)(input_tensor) if strides > 1 else input_tensor\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=1, use_bias=False,\n",
    "               name=name_base + '_1_conv')(preact)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name_base + '_2_pad')(x)\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING, strides=strides,\n",
    "               use_bias=False, name=name_base + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=name_base + '_3_conv')(x)\n",
    "\n",
    "    x = Add(name=name_base + '_out')([shortcut, x])\n",
    "    return x\n",
    "\n",
    "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=1):\n",
    "\n",
    "    filters1, filters2, filters3 = filters\n",
    "\n",
    "    if IMAGE_ORDERING == 'channels_last':\n",
    "        bn_axis = 3\n",
    "    else:\n",
    "        bn_axis = 1\n",
    "    \n",
    "    name_base = 'conv' + str(stage) + '_' + 'block' + block  \n",
    "        \n",
    "    preact = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                       name=name_base + '_preact_bn')(input_tensor)\n",
    "    preact = Activation('relu', name=name_base + '_preact_relu')(preact)\n",
    "    \n",
    "    shortcut = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING, \n",
    "                      strides=strides, name=name_base + '_0_conv')(preact)\n",
    "\n",
    "    x = Conv2D(filters1, (1, 1), data_format=IMAGE_ORDERING, strides=1, use_bias=False,\n",
    "               name=name_base + '_1_conv')(preact)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_1_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_1_relu')(x)\n",
    "\n",
    "    x = ZeroPadding2D(padding=((1, 1), (1, 1)), name=name_base + '_2_pad')(x)\n",
    "    x = Conv2D(filters2, kernel_size, data_format=IMAGE_ORDERING, strides=strides,\n",
    "               use_bias=False, name=name_base + '_2_conv')(x)\n",
    "    x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name_base + '_2_bn')(x)\n",
    "    x = Activation('relu', name=name_base + '_2_relu')(x)\n",
    "\n",
    "    x = Conv2D(filters3, (1, 1), data_format=IMAGE_ORDERING,\n",
    "               name=name_base + '_3_conv')(x)\n",
    "\n",
    "    x = Add(name=name_base + '_out')([shortcut, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_height = input_width = INPUT_SIZE\n",
    "n_classes = classes = CLASS_NUM\n",
    "use_bias = True # True for ResNet and ResNetV2, False for ResNeXt\n",
    "bn_axis = 3 if IMAGE_ORDERING == 'channels_last' else 1\n",
    "\n",
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    img_input = Input(shape=(3, input_height, input_width))\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    img_input = Input(shape=(input_height, input_width, 3))\n",
    "\n",
    "### conv1 ###\n",
    "x = ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "x = Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "f0 = x\n",
    "x = ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "x = MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "f1 = x\n",
    "\n",
    "### conv2 ###\n",
    "x = conv_block(x, 3, [64, 64, 256], stage=2, block='1', strides=(1, 1))\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='2')\n",
    "x = identity_block(x, 3, [64, 64, 256], stage=2, block='3', strides=2)\n",
    "f2 = x\n",
    "#f2 = one_side_pad(x)\n",
    "\n",
    "### conv3 ###\n",
    "x = conv_block(x, 3, [128, 128, 512], stage=3, block='1')\n",
    "for i in range(6):\n",
    "    x = identity_block(x, 3, [128, 128, 512], stage=3, block=str(i+2))\n",
    "x = identity_block(x, 3, [128, 128, 512], stage=3, block='8', strides=2)\n",
    "f3 = x\n",
    "\n",
    "### conv4 ###\n",
    "x = conv_block(x, 3, [256, 256, 1024], stage=4, block='1')\n",
    "for i in range(34):\n",
    "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block=str(i+2))\n",
    "x = identity_block(x, 3, [256, 256, 1024], stage=4, block='36', strides=2)\n",
    "f4 = x\n",
    "\n",
    "### conv5 ###\n",
    "x = conv_block(x, 3, [512, 512, 2048], stage=5, block='1')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='2')\n",
    "x = identity_block(x, 3, [512, 512, 2048], stage=5, block='3', strides=1)\n",
    "f5 = x\n",
    "\n",
    "x = BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name='post_bn')(x)\n",
    "x = Activation('relu', name='post_relu')(x)\n",
    "x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "x = Dense(1000, activation='softmax', name='probs')(x) \n",
    "    # 為了能對Eecoder載入keras.applications用imagenet預訓練的參數，因此輸出層的神經元設成1000而非標記的類別數量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 對Eecoder載入keras.applications用imagenet預訓練的參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_WEIGHTS_PATH = (\n",
    "    'https://github.com/keras-team/keras-applications/'\n",
    "    'releases/download/resnet/')\n",
    "WEIGHTS_HASHES = {\n",
    "    'resnet50': ('2cb95161c43110f7111970584f804107',\n",
    "                 '4d473c1dd8becc155b73f8504c6f6626'),\n",
    "    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',\n",
    "                  '88cf7a10940856eca736dc7b7e228a21'),\n",
    "    'resnet152': ('100835be76be38e30d865e96f2aaae62',\n",
    "                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),\n",
    "    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',\n",
    "                   'fac2f116257151a9d068a22e544a4917'),\n",
    "    'resnet101v2': ('6343647c601c52e1368623803854d971',\n",
    "                    'c0ed64b8031c3730f411d2eb4eea35b5'),\n",
    "    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',\n",
    "                    'ed17cf2e0169df9d443503ef94b23b33'),\n",
    "    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',\n",
    "                  '62527c363bdd9ec598bed41947b379fc'),\n",
    "    'resnext101': ('34fb605428fcc7aa4d62f44404c11509',\n",
    "                   '0f678c91647380debd923963594981b3')\n",
    "}\n",
    "\n",
    "model_name='resnet152v2'\n",
    "file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "file_hash = WEIGHTS_HASHES[model_name][0]\n",
    "\n",
    "weights_path = keras.utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)\n",
    "Model(img_input, x).load_weights(weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decoder (這裡我有為了讓輸出大小和輸入大小保持一致新增一個含有上取樣層的block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    MERGE_AXIS = 1\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    MERGE_AXIS = -1\n",
    "\n",
    "o = f4\n",
    "\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(512, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f3], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(256, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f2], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f1], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(128, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (concatenate([o, f0], axis=MERGE_AXIS))\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = (UpSampling2D((2, 2), data_format=IMAGE_ORDERING))(o)\n",
    "o = (ZeroPadding2D((1, 1), data_format=IMAGE_ORDERING))(o)\n",
    "#o = (Conv2D(32, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (Conv2D(64, (3, 3), padding='valid', data_format=IMAGE_ORDERING))(o)\n",
    "o = (BatchNormalization())(o)\n",
    "\n",
    "o = Conv2D(n_classes, (3, 3), padding='same', data_format=IMAGE_ORDERING)(o) # 輸出層\n",
    "\n",
    "## 模仿 keras_segmentation 在輸出層之後額外添加這幾層 ###\n",
    "if IMAGE_ORDERING == 'channels_first':\n",
    "    o = (Reshape((n_classes, INPUT_SIZE * INPUT_SIZE)))(o)\n",
    "    o = (Permute((2, 1)))(o)\n",
    "elif IMAGE_ORDERING == 'channels_last':\n",
    "    o = (Reshape((INPUT_SIZE * INPUT_SIZE, n_classes)))(o)\n",
    "o = (Activation('softmax'))(o)\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(img_input, o)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 查看模型架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 518, 518, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 256, 256, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 258, 258, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 128, 128, 64) 0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 128, 128, 64) 256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 128, 128, 64) 0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 128, 128, 64) 4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 128, 128, 64) 0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 128, 128, 64) 0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 128, 128, 256 0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 128, 128, 256 0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 128, 128, 64) 0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 128, 128, 64) 36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 128, 128, 64) 0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 128, 128, 256 16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 128, 128, 256 0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 128, 128, 256 1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 128, 128, 256 0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 128, 128, 64) 16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 128, 128, 64) 256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 128, 128, 64) 0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 130, 130, 64) 0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 64, 64, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 64, 64, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 64, 64, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 64, 64, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 64, 64, 256)  0           max_pooling2d_1[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 64, 64, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 64, 64, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 64, 64, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 64, 64, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 64, 64, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 64, 64, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 64, 64, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 64, 64, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 64, 64, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 64, 64, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 64, 64, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 64, 64, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 64, 64, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 64, 64, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 64, 64, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 64, 64, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 64, 64, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_relu (Activation (None, 64, 64, 128)  0           conv3_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_out (Add)          (None, 64, 64, 512)  0           conv3_block4_out[0][0]           \n",
      "                                                                 conv3_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 64, 64, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_relu (Activation (None, 64, 64, 128)  0           conv3_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_out (Add)          (None, 64, 64, 512)  0           conv3_block5_out[0][0]           \n",
      "                                                                 conv3_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 64, 64, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 64, 64, 128)  147456      conv3_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_relu (Activation (None, 64, 64, 128)  0           conv3_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_3_conv (Conv2D)    (None, 64, 64, 512)  66048       conv3_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_out (Add)          (None, 64, 64, 512)  0           conv3_block6_out[0][0]           \n",
      "                                                                 conv3_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_bn (BatchNo (None, 64, 64, 512)  2048        conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_preact_relu (Activ (None, 64, 64, 512)  0           conv3_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 64, 64, 128)  65536       conv3_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 64, 64, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 64, 64, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_pad (ZeroPadding (None, 66, 66, 128)  0           conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 32, 32, 128)  147456      conv3_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_bn (BatchNormali (None, 32, 32, 128)  512         conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_relu (Activation (None, 32, 32, 128)  0           conv3_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 512)  0           conv3_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_3_conv (Conv2D)    (None, 32, 32, 512)  66048       conv3_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_out (Add)          (None, 32, 32, 512)  0           max_pooling2d_2[0][0]            \n",
      "                                                                 conv3_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 32, 32, 512)  2048        conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 32, 32, 512)  0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 32, 32, 256)  131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 32, 32, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 32, 32, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 32, 32, 1024) 525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 32, 32, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 32, 32, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 32, 32, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 32, 32, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 32, 32, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 32, 32, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 32, 32, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 32, 32, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 32, 32, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 32, 32, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 32, 32, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 32, 32, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 32, 32, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 32, 32, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 32, 32, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block7_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block7_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 32, 32, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block7_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 32, 32, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Add)          (None, 32, 32, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block8_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block8_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 32, 32, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block8_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 32, 32, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Add)          (None, 32, 32, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_bn (BatchNo (None, 32, 32, 1024) 4096        conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_preact_relu (Activ (None, 32, 32, 1024) 0           conv4_block9_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 32, 32, 256)  262144      conv4_block9_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 32, 32, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_pad (ZeroPadding (None, 34, 34, 256)  0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 32, 32, 256)  589824      conv4_block9_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 32, 32, 256)  1024        conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 32, 32, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 32, 32, 1024) 263168      conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Add)          (None, 32, 32, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block10_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block10_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block10_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Add)         (None, 32, 32, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block11_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block11_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block11_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Add)         (None, 32, 32, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block12_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block12_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block12_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Add)         (None, 32, 32, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block13_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block13_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block13_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Add)         (None, 32, 32, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block14_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block14_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block14_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Add)         (None, 32, 32, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block15_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block15_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block15_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Add)         (None, 32, 32, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block16_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block16_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block16_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Add)         (None, 32, 32, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block17_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block17_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block17_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Add)         (None, 32, 32, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block18_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block18_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block18_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Add)         (None, 32, 32, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block19_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block19_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block19_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Add)         (None, 32, 32, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block20_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block20_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block20_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Add)         (None, 32, 32, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block21_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block21_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block21_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Add)         (None, 32, 32, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block22_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block22_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block22_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Add)         (None, 32, 32, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block23_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block23_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block23_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Add)         (None, 32, 32, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block24_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block24_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block24_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block24_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block24_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_out (Add)         (None, 32, 32, 1024) 0           conv4_block23_out[0][0]          \n",
      "                                                                 conv4_block24_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block24_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block25_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block25_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block25_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block25_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block25_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_out (Add)         (None, 32, 32, 1024) 0           conv4_block24_out[0][0]          \n",
      "                                                                 conv4_block25_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block25_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block26_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block26_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block26_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block26_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block26_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_out (Add)         (None, 32, 32, 1024) 0           conv4_block25_out[0][0]          \n",
      "                                                                 conv4_block26_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block26_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block27_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block27_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block27_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block27_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block27_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_out (Add)         (None, 32, 32, 1024) 0           conv4_block26_out[0][0]          \n",
      "                                                                 conv4_block27_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block27_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block28_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block28_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block28_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block28_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block28_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_out (Add)         (None, 32, 32, 1024) 0           conv4_block27_out[0][0]          \n",
      "                                                                 conv4_block28_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block28_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block29_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block29_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block29_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block29_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block29_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_out (Add)         (None, 32, 32, 1024) 0           conv4_block28_out[0][0]          \n",
      "                                                                 conv4_block29_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block29_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block30_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block30_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block30_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block30_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block30_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_out (Add)         (None, 32, 32, 1024) 0           conv4_block29_out[0][0]          \n",
      "                                                                 conv4_block30_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block30_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block31_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block31_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block31_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block31_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block31_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_out (Add)         (None, 32, 32, 1024) 0           conv4_block30_out[0][0]          \n",
      "                                                                 conv4_block31_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block31_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block32_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block32_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block32_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block32_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block32_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_out (Add)         (None, 32, 32, 1024) 0           conv4_block31_out[0][0]          \n",
      "                                                                 conv4_block32_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block32_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block33_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block33_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block33_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block33_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block33_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_out (Add)         (None, 32, 32, 1024) 0           conv4_block32_out[0][0]          \n",
      "                                                                 conv4_block33_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block33_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block34_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block34_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block34_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block34_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block34_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_out (Add)         (None, 32, 32, 1024) 0           conv4_block33_out[0][0]          \n",
      "                                                                 conv4_block34_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block34_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block35_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block35_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 32, 32, 256)  589824      conv4_block35_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_relu (Activatio (None, 32, 32, 256)  0           conv4_block35_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_3_conv (Conv2D)   (None, 32, 32, 1024) 263168      conv4_block35_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_out (Add)         (None, 32, 32, 1024) 0           conv4_block34_out[0][0]          \n",
      "                                                                 conv4_block35_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_bn (BatchN (None, 32, 32, 1024) 4096        conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_preact_relu (Acti (None, 32, 32, 1024) 0           conv4_block36_preact_bn[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 32, 32, 256)  262144      conv4_block36_preact_relu[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 32, 32, 256)  1024        conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 32, 32, 256)  0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_pad (ZeroPaddin (None, 34, 34, 256)  0           conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 16, 16, 256)  589824      conv4_block36_2_pad[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_bn (BatchNormal (None, 16, 16, 256)  1024        conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_relu (Activatio (None, 16, 16, 256)  0           conv4_block36_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 1024) 0           conv4_block35_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_3_conv (Conv2D)   (None, 16, 16, 1024) 263168      conv4_block36_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_out (Add)         (None, 16, 16, 1024) 0           max_pooling2d_3[0][0]            \n",
      "                                                                 conv4_block36_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 18, 18, 1024) 0           conv4_block36_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 16, 16, 512)  4719104     zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 16, 16, 512)  2048        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 32, 32, 512)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 32, 1024) 0           up_sampling2d_1[0][0]            \n",
      "                                                                 conv3_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 34, 34, 1024) 0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 32, 32, 256)  2359552     zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 64, 64, 256)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           up_sampling2d_2[0][0]            \n",
      "                                                                 conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPadding2D (None, 66, 66, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 64, 64, 128)  589952      zero_padding2d_3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 128, 128, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 128, 128, 192 0           up_sampling2d_3[0][0]            \n",
      "                                                                 pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_4 (ZeroPadding2D (None, 130, 130, 192 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 128 221312      zero_padding2d_4[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 128, 128, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 256, 256, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 256, 256, 192 0           up_sampling2d_4[0][0]            \n",
      "                                                                 conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 258, 258, 192 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 256, 256, 64) 110656      zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 256, 256, 64) 256         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 512, 512, 64) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 514, 514, 64) 0           up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 512, 512, 64) 36928       zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 512, 512, 64) 256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 512, 512, 2)  1154        batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (None, 262144, 2)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 262144, 2)    0           reshape_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 51,383,554\n",
      "Trainable params: 51,257,986\n",
      "Non-trainable params: 125,568\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 載入模型參數(optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights('DATA_0811_2\\WW600WL100\\\\Model_0905_V2\\\\ResNet152V2-Unet_100.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam, Adadelta\n",
    "model.compile(loss = 'categorical_crossentropy',\n",
    "              optimizer = Adadelta(lr = 1.0),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "print(K.eval(model.optimizer.lr)) # 確保是1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########## 即將用該資料集進行訓練：DATA_0811_2\\WW600WL100 ##########\n",
      "-----建立新資料夾：DATA_0811_2\\WW600WL100\\Model_0905_V2-----\n",
      "Epoch 1/100\n",
      "512/512 [==============================] - 303s 591ms/step - loss: 0.1196 - accuracy: 0.9718\n",
      "Epoch 2/100\n",
      "512/512 [==============================] - 258s 505ms/step - loss: 0.0493 - accuracy: 0.9885\n",
      "Epoch 3/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 0.0490 - accuracy: 0.9884\n",
      "Epoch 4/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0322 - accuracy: 0.9911\n",
      "Epoch 5/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0153 - accuracy: 0.9953\n",
      "Epoch 6/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0073 - accuracy: 0.9976\n",
      "Epoch 7/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0086 - accuracy: 0.9974\n",
      "Epoch 8/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 0.0087 - accuracy: 0.9972\n",
      "Epoch 9/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0093 - accuracy: 0.9970\n",
      "Epoch 10/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 11/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0036 - accuracy: 0.9988\n",
      "Epoch 12/100\n",
      "512/512 [==============================] - 258s 505ms/step - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 13/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 14/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0032 - accuracy: 0.9989\n",
      "Epoch 15/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0055 - accuracy: 0.9983\n",
      "Epoch 16/100\n",
      "512/512 [==============================] - 259s 505ms/step - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 17/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0046 - accuracy: 0.9985\n",
      "Epoch 18/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0038 - accuracy: 0.9987\n",
      "Epoch 19/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0035 - accuracy: 0.9989\n",
      "Epoch 20/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0024 - accuracy: 0.9991\n",
      "Epoch 21/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0025 - accuracy: 0.9992\n",
      "Epoch 22/100\n",
      "512/512 [==============================] - 259s 505ms/step - loss: 0.0034 - accuracy: 0.9989\n",
      "Epoch 23/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0021 - accuracy: 0.9993\n",
      "Epoch 24/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0022 - accuracy: 0.9993\n",
      "Epoch 25/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 26/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0018 - accuracy: 0.9994\n",
      "Epoch 27/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 28/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 29/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 30/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0015 - accuracy: 0.9994\n",
      "Epoch 31/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0031 - accuracy: 0.9990\n",
      "Epoch 32/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0020 - accuracy: 0.9992\n",
      "Epoch 33/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 34/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 35/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 36/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 37/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 38/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 40/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 0.0014 - accuracy: 0.9994\n",
      "Epoch 41/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0019 - accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "512/512 [==============================] - 259s 505ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 43/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 44/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 45/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 46/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 47/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 48/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0016 - accuracy: 0.9994\n",
      "Epoch 49/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0015 - accuracy: 0.9995\n",
      "Epoch 50/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 51/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 52/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 53/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0014 - accuracy: 0.9995\n",
      "Epoch 54/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 55/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 56/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 57/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 58/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 59/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 60/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 61/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.6691e-04 - accuracy: 0.9996\n",
      "Epoch 62/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 63/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 64/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 65/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 66/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0017 - accuracy: 0.9994\n",
      "Epoch 67/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0013 - accuracy: 0.9995\n",
      "Epoch 68/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.8867e-04 - accuracy: 0.9996\n",
      "Epoch 69/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.7881e-04 - accuracy: 0.9996\n",
      "Epoch 70/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 71/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0012 - accuracy: 0.9996\n",
      "Epoch 72/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 0.0012 - accuracy: 0.9995\n",
      "Epoch 73/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.4784e-04 - accuracy: 0.9996\n",
      "Epoch 74/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 8.9455e-04 - accuracy: 0.9996\n",
      "Epoch 75/100\n",
      "512/512 [==============================] - 260s 508ms/step - loss: 9.8892e-04 - accuracy: 0.9996\n",
      "Epoch 76/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.7517e-04 - accuracy: 0.9996\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0010 - accuracy: 0.9996\n",
      "Epoch 78/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 8.8580e-04 - accuracy: 0.9996\n",
      "Epoch 79/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 0.0011 - accuracy: 0.9996\n",
      "Epoch 80/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.5032e-04 - accuracy: 0.9996\n",
      "Epoch 81/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.8110e-04 - accuracy: 0.9996\n",
      "Epoch 82/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.6342e-04 - accuracy: 0.9996\n",
      "Epoch 83/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.7359e-04 - accuracy: 0.9996\n",
      "Epoch 84/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.6664e-04 - accuracy: 0.9996\n",
      "Epoch 85/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 8.7170e-04 - accuracy: 0.9997\n",
      "Epoch 86/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.3810e-04 - accuracy: 0.9996\n",
      "Epoch 87/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 8.9952e-04 - accuracy: 0.9996\n",
      "Epoch 88/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 8.7813e-04 - accuracy: 0.9997\n",
      "Epoch 89/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.5089e-04 - accuracy: 0.9996\n",
      "Epoch 90/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 8.4099e-04 - accuracy: 0.9997\n",
      "Epoch 91/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 8.5993e-04 - accuracy: 0.9997\n",
      "Epoch 92/100\n",
      "512/512 [==============================] - 259s 505ms/step - loss: 7.9728e-04 - accuracy: 0.9997\n",
      "Epoch 93/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 8.2805e-04 - accuracy: 0.9997\n",
      "Epoch 94/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.0934e-04 - accuracy: 0.9996\n",
      "Epoch 95/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 8.7542e-04 - accuracy: 0.9997\n",
      "Epoch 96/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 9.0274e-04 - accuracy: 0.9996\n",
      "Epoch 97/100\n",
      "512/512 [==============================] - 259s 507ms/step - loss: 9.9550e-04 - accuracy: 0.9996\n",
      "Epoch 98/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 9.6493e-04 - accuracy: 0.9996\n",
      "Epoch 99/100\n",
      "512/512 [==============================] - 259s 506ms/step - loss: 8.1892e-04 - accuracy: 0.9997\n",
      "Epoch 100/100\n",
      "512/512 [==============================] - 260s 507ms/step - loss: 7.8801e-04 - accuracy: 0.9997\n",
      "花費時間(秒)：26288.676398038864\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "print(f'########## 即將用該資料集進行訓練：{dataset_dir} ##########')\n",
    "\n",
    "if start_from_latest_checkpoints:\n",
    "    try:\n",
    "        model.load_weights(\n",
    "            os.path.join(\n",
    "                checkpoints_path, \n",
    "                model_name + '_' + str(max([int(i.split('_')[-1][:-3]) for i in os.listdir(checkpoints_path)])) + '.h5'\n",
    "            )\n",
    "        )\n",
    "    except:\n",
    "        print('Model weights not found!')\n",
    "\n",
    "if not os.path.exists(checkpoints_path):\n",
    "    os.makedirs(checkpoints_path)\n",
    "    print('-----建立新資料夾：' + checkpoints_path + '-----') \n",
    "\n",
    "\n",
    "model.fit_generator(\n",
    "    train_gen,\n",
    "    steps_per_epoch = 512, \n",
    "    #steps_per_epoch = len(x_train) // BATCH_SIZE,\n",
    "    epochs = EPOCHS,\n",
    "    verbose = 1,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "ed = time.time()\n",
    "spend_time = ed - st\n",
    "print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型預測結果(測試集)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12656/12656 [15:55<00:00, 13.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from evaluate import *\n",
    "preds = predict_from_folder(model, 'DATA_0811_2\\\\WW600WL100\\\\test\\\\images', INPUT_SIZE, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------開始計算各項預測指標----------\n",
      "目前進度：第500張照片\n",
      "目前進度：第1000張照片\n",
      "目前進度：第1500張照片\n",
      "目前進度：第2000張照片\n",
      "目前進度：第2500張照片\n",
      "目前進度：第3000張照片\n",
      "目前進度：第3500張照片\n",
      "目前進度：第4000張照片\n",
      "目前進度：第4500張照片\n",
      "目前進度：第5000張照片\n",
      "目前進度：第5500張照片\n",
      "目前進度：第6000張照片\n",
      "目前進度：第6500張照片\n",
      "目前進度：第7000張照片\n",
      "目前進度：第7500張照片\n",
      "目前進度：第8000張照片\n",
      "目前進度：第8500張照片\n",
      "目前進度：第9000張照片\n",
      "目前進度：第9500張照片\n",
      "目前進度：第10000張照片\n",
      "目前進度：第10500張照片\n",
      "目前進度：第11000張照片\n",
      "目前進度：第11500張照片\n",
      "目前進度：第12000張照片\n",
      "目前進度：第12500張照片\n",
      "total case number: 12656\n",
      "訓練集預測結果：\n",
      "average Dice score per case of kidney:  0.9596\n",
      "average recall of kidney:  0.9425\n",
      "average precision of kidney:  0.9789\n",
      "global dice score of kidney:  0.9526\n",
      "\n",
      "混淆矩陣：\n",
      "True Positive: 4021\n",
      "False Positive: 72\n",
      "False Negative: 98\n",
      "True Negative: 8465\n",
      "花費時間(秒)：961.4984998703003\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "result = evaluate_model(\n",
    "    image_dir = os.path.join(dataset_dir, 'test', 'images'), \n",
    "    label_dir = os.path.join(dataset_dir, 'test', 'annotations_tumor as kidney'), \n",
    "    checkpoints_path = None,\n",
    "    calculate_predicting_indicators = True,\n",
    "    output_predicted_result = False, \n",
    "    segment_out_predicted_region_from_original_images = False, \n",
    "    roi_description = 'tumor as kidney', \n",
    "    preds = preds)\n",
    "\n",
    "print('訓練集預測結果：')\n",
    "print(f'average Dice score per case of kidney: {result[0]: .4f}')\n",
    "print(f'average recall of kidney: {result[1]: .4f}')\n",
    "print(f'average precision of kidney: {result[2]: .4f}')\n",
    "print(f'global dice score of kidney: {result[3]: .4f}')\n",
    "print('')\n",
    "print('混淆矩陣：')\n",
    "print(f'True Positive: {result[-4]}')\n",
    "print(f'False Positive: {result[-3]}')\n",
    "print(f'False Negative: {result[-2]}')\n",
    "print(f'True Negative: {result[-1]}')\n",
    "\n",
    "ed = time.time()\n",
    "spend_time = ed - st\n",
    "print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試集各病患的 Dice score:\n",
      "case150:  0.9766\n",
      "case151:  0.8081\n",
      "case152:  0.9799\n",
      "case153:  0.9788\n",
      "case154:  0.9587\n",
      "case155:  0.9593\n",
      "case156:  0.9716\n",
      "case157:  0.9700\n",
      "case158:  0.9744\n",
      "case159:  0.9714\n",
      "case160:  0.9608\n",
      "case161:  0.9533\n",
      "case162:  0.9626\n",
      "case163:  0.9720\n",
      "case164:  0.9669\n",
      "case165:  0.9671\n",
      "case166:  0.9706\n",
      "case167:  0.9833\n",
      "case168:  0.9630\n",
      "case169:  0.9745\n",
      "case170:  0.9533\n",
      "case171:  0.9761\n",
      "case172:  0.9522\n",
      "case173:  0.9634\n",
      "case174:  0.9740\n",
      "case175:  0.9623\n",
      "case176:  0.9614\n",
      "case177:  0.9398\n",
      "case178:  0.8938\n",
      "case179:  0.9743\n",
      "case181:  0.9677\n",
      "case182:  0.9635\n",
      "case183:  0.9648\n",
      "case184:  0.9244\n",
      "case185:  0.9779\n",
      "case186:  0.9759\n",
      "case187:  0.9299\n",
      "case188:  0.9593\n",
      "case189:  0.9076\n",
      "case190:  0.9597\n",
      "case191:  0.9729\n",
      "case192:  0.9475\n",
      "case193:  0.9787\n",
      "case194:  0.9469\n",
      "case195:  0.9689\n",
      "case196:  0.9811\n",
      "case197:  0.9450\n",
      "case198:  0.9579\n",
      "case199:  0.9543\n",
      "case200:  0.9666\n",
      "case201:  0.9801\n",
      "case202:  0.9717\n",
      "case204:  0.9781\n",
      "case205:  0.9541\n",
      "case206:  0.9490\n",
      "case207:  0.9744\n",
      "case208:  0.9464\n",
      "case209:  0.9781\n"
     ]
    }
   ],
   "source": [
    "f = open(\"DATA_0811_2\\\\patient indices of testing set - KiTS.txt\", \"r\")\n",
    "test_patient_idx = f.read().splitlines()\n",
    "f.close()\n",
    "\n",
    "dice_score_list = result[5]\n",
    "print('測試集各病患的 Dice score:')\n",
    "for idx, i in enumerate(dice_score_list):\n",
    "    print(f'case{test_patient_idx[idx]}: {i: .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# st = time.time()\n",
    "\n",
    "# from evaluate import *\n",
    "# _ = evaluate_model(\n",
    "#     image_dir = os.path.join(dataset_dir, 'test', 'images'), \n",
    "#     label_dir = os.path.join(dataset_dir, 'test', 'annotations_tumor as kidney'), \n",
    "#     checkpoints_path = None,\n",
    "#     calculate_predicting_indicators = False,\n",
    "#     output_predicted_result = True, \n",
    "#     segment_out_predicted_region_from_original_images = True, \n",
    "#     roi_description = 'tumor as kidney', \n",
    "#     preds = preds\n",
    "# )\n",
    "\n",
    "# ed = time.time()\n",
    "# spend_time = ed - st\n",
    "# print('花費時間(秒)：' + str(spend_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# show_result(\n",
    "#     target_dataset_base_dir = 'DATA_0811_2\\\\WW600WL100\\\\test',\n",
    "#     result_num = 10,\n",
    "#     roi_description = 'tumor as kidney', \n",
    "#     roi_name_chinese = '腎臟',\n",
    "#     show_predicted_result = True,\n",
    "#     show_segmentation_result = True, \n",
    "#     image_scale = 4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
